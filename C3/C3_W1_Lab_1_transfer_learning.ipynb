{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "C3_W1_Lab_1_transfer_learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAT2ez7LuUEa"
      },
      "source": [
        "# Transfer Learning"
      ],
      "id": "sAT2ez7LuUEa"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "metric-approach"
      },
      "source": [
        "import numpy                      as np\n",
        "import tensorflow                 as tf\n",
        "from tensorflow.keras.models      import Model\n",
        "from tensorflow.keras.layers      import Dense, Flatten, Input\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow_datasets as tds\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n"
      ],
      "id": "metric-approach",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2tayQ3GqVub"
      },
      "source": [
        "## Data Acquisition"
      ],
      "id": "C2tayQ3GqVub"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prsLPOj4qbCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9912960d-a73a-4d57-c47c-7403487c17f9"
      },
      "source": [
        "(train_img, train_label), (test_img, test_label) = tf.keras.datasets.cifar10.load_data()"
      ],
      "id": "prsLPOj4qbCx",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGpPtod6sAWx"
      },
      "source": [
        "def pre_process(input_img):\n",
        "    input_img = input_img.astype(float)\n",
        "    return preprocess_input(input_img)\n",
        "\n",
        "\n",
        "train_img = pre_process(train_img)\n",
        "test_img = pre_process(test_img)"
      ],
      "id": "jGpPtod6sAWx",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCssj7QLu3NL",
        "outputId": "4ff121fe-0c2a-4a58-91a3-dfaab34ad5c7"
      },
      "source": [
        "test_img.shape"
      ],
      "id": "lCssj7QLu3NL",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9lXfqphH8KG"
      },
      "source": [
        "## Model"
      ],
      "id": "u9lXfqphH8KG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLtKNqCnLiMU",
        "outputId": "81a17f23-ed66-4e09-e29f-9b03b88614bf"
      },
      "source": [
        "'''\n",
        "Feature Extraction is performed by ResNet50 pretrained on imagenet weights. \n",
        "Input size is 224 x 224.\n",
        "'''\n",
        "\n",
        "# instantiate Resnet50\n",
        "def feature_extract(inp):\n",
        "  feature_extract = ResNet50(input_shape=(224,224,3), \n",
        "                             include_top = False, \n",
        "                             weights = 'imagenet')(inp)\n",
        "  return feature_extract  \n",
        "\n",
        "\n",
        "\n",
        "def classifier(inp):\n",
        "  x = tf.keras.layers.GlobalAveragePooling2D()(inp)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(512, activation='relu')(x)\n",
        "  x = Dense(10, activation='softmax')(x)  \n",
        "  return x\n",
        "\n",
        "\n",
        "'''\n",
        "Since input image size is (32 x 32), first upsample the image by factor of (7x7) to transform it to (224 x 224)\n",
        "Connect the feature extraction and \"classifier\" layers to build the model.\n",
        "'''\n",
        "def final_model():\n",
        "  inputs = Input(shape= (32,32,3))\n",
        "  x = tf.keras.layers.UpSampling2D(size=(7,7))(inputs)\n",
        "  x = feature_extract(x)\n",
        "  x = classifier(x)\n",
        "\n",
        "  model = Model(inputs, x)\n",
        "  return model\n",
        "\n",
        "\n",
        "model = final_model()  \n",
        "\n"
      ],
      "id": "xLtKNqCnLiMU",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xon4OrwW4o7i",
        "outputId": "c5214996-f19d-43a3-cf31-a9fe72c19e76"
      },
      "source": [
        "model.summary()\n",
        "model.compile(optimizer='SGD', \n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics = ['accuracy'])"
      ],
      "id": "xon4OrwW4o7i",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 24,641,930\n",
            "Trainable params: 24,588,810\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f7UTIXFjOhb",
        "outputId": "3f0f3ca6-67a5-4299-ec74-2867d20857a8"
      },
      "source": [
        "history = model.fit(\n",
        "            train_img, train_label,\n",
        "            validation_data=(test_img, test_label),\n",
        "            epochs=2,\n",
        "            verbose=1)"
      ],
      "id": "_f7UTIXFjOhb",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1563/1563 [==============================] - 576s 345ms/step - loss: 0.5712 - accuracy: 0.8081 - val_loss: 0.1819 - val_accuracy: 0.9390\n",
            "Epoch 2/2\n",
            "1563/1563 [==============================] - 538s 345ms/step - loss: 0.0964 - accuracy: 0.9679 - val_loss: 0.1456 - val_accuracy: 0.9518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flDEBkmGfJZ9"
      },
      "source": [
        ""
      ],
      "id": "flDEBkmGfJZ9",
      "execution_count": 7,
      "outputs": []
    }
  ]
}